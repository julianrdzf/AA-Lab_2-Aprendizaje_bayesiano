{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m archivo \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDatos/chat.txt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39m#Se cargan el archivo en un data frame\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "archivo = 'Datos/chat.txt'\n",
    "\n",
    "#Se cargan el archivo en un data frame\n",
    "with open(archivo, encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "df_data = pd.DataFrame()    \n",
    "df_data['crudo']=pd.DataFrame(lines)\n",
    "\n",
    "#Se separan las columnas fecha, autor y texto\n",
    "df_data['fecha'] = df_data.crudo.str.split(r'[\\[\\]]', expand=True,regex=True)[1]\n",
    "df_data['autor'] = df_data.crudo.str.split(r'\\[*\\] |: ', expand=True,regex=True)[1]\n",
    "df_data['texto'] = df_data.crudo.str.split(r'\\][^:]+: ', expand=True,regex=True)[1]\n",
    "#df_data.drop('crudo', inplace=True, axis=1)\n",
    "\n",
    "#Se quitan las filas con adjuntos omitidos\n",
    "df_data=df_data.drop(df_data[df_data['texto']=='‎imagen omitida\\n'].index)\n",
    "df_data=df_data.drop(df_data[df_data['texto']=='‎audio omitido\\n'].index)\n",
    "df_data=df_data.drop(df_data[df_data['texto']=='‎sticker omitido\\n'].index)\n",
    "\n",
    "#se pasa todo a minúsculas\n",
    "df_data['texto limpio']=df_data.texto.str.lower()\n",
    "\n",
    "#Se cambia cualquier cosa que no sea una palabra por un espacio\n",
    "df_data['texto limpio']=df_data['texto limpio'].str.replace(r'[\\W]+',' ', regex=True)\n",
    "\n",
    "#Se eliminan los espacios al final de linea\n",
    "df_data['texto limpio']=df_data['texto limpio'].str.replace(r'\\s$','', regex=True)\n",
    "\n",
    "#Se eliminan los espacios al comienzo de linea\n",
    "df_data['texto limpio']=df_data['texto limpio'].str.replace(r'^\\s','', regex=True)\n",
    "\n",
    "#se genera una columna con la lista de palabras de cada fila\n",
    "df_data['palabras']=df_data['texto limpio'].str.lower().str.split(r'[\\W]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones para generar los diccionarios y agregar listas de palabras\n",
    "\n",
    "#Suma una aparición a un diccionario PD\n",
    "def sumar_aparicion(dic, pal_objetivo):\n",
    "    if dic.get(pal_objetivo) is not None:        \n",
    "        if dic[pal_objetivo].get('_apariciones') is not None:\n",
    "            dic[pal_objetivo]['_apariciones']+=1\n",
    "        else:\n",
    "            dic[pal_objetivo]['_apariciones']=1\n",
    "    else:\n",
    "        dic[pal_objetivo]={}\n",
    "        dic[pal_objetivo]['_apariciones']=1\n",
    "\n",
    "#Agrega una palabra a un diccionario PD\n",
    "def agregar_palabra(dic, pal_objetivo, pal_agregar):\n",
    "    if dic.get(pal_objetivo) is not None:\n",
    "        if dic[pal_objetivo].get(pal_agregar) is not None:\n",
    "            dic[pal_objetivo][pal_agregar]+=1            \n",
    "        else:\n",
    "            dic[pal_objetivo][pal_agregar]=1\n",
    "            \n",
    "        if dic[pal_objetivo].get('_total') is not None:    \n",
    "            dic[pal_objetivo]['_total']+=1\n",
    "        else:\n",
    "            dic[pal_objetivo]['_total']=1\n",
    "    else:\n",
    "        dic[pal_objetivo]={}\n",
    "        dic[pal_objetivo][pal_agregar]=1\n",
    "        dic[pal_objetivo]['_total']=1\n",
    "\n",
    "#Agrega una lista de palabras a un diccionario PD\n",
    "def agregar_palabras_PD(dic, lista, N):\n",
    "        \n",
    "    for i in range(len(lista)):\n",
    "        agregadas = []\n",
    "        for n in range(1,N+1):            \n",
    "            if (i-n>=0):\n",
    "                #Verifico que no sean dos palabras consecutivas iguales\n",
    "                if not(lista[i-n] in agregadas):\n",
    "                    agregar_palabra(dic,lista[i],lista[i-n])\n",
    "                    agregadas.append(lista[i-n])\n",
    "        sumar_aparicion(dic, lista[i])\n",
    "\n",
    "#Agrega un lista de palabras a un diccionario P    \n",
    "def agregar_palabras_P(dic,lista):\n",
    "    for i in range(len(lista)):\n",
    "        if dic.get(lista[i]) is not None:        \n",
    "            dic[lista[i]]+=1\n",
    "        else:\n",
    "            dic[lista[i]]=1\n",
    "        dic['_total']+=1\n",
    "\n",
    "#Genera un diccionario P a partir de un Data Frame que contiene un columna con listar de palabras     \n",
    "def entrenar_P(df):\n",
    "    P={}\n",
    "    P['_total']=0\n",
    "    for lista in df:\n",
    "        agregar_palabras_P(P, lista)\n",
    "    return P\n",
    "  \n",
    "#Genera un diccionario PD teniendo en cuenta N a partir de un Data Frame que contiene una columna con lista de palabras     \n",
    "def entrenar_PD(df, N):    \n",
    "    PD={}    \n",
    "    for lista in df:\n",
    "        agregar_palabras_PD(PD, lista, N)\n",
    "    return PD\n",
    "\n",
    "#Convierte una lista a minúsculas\n",
    "def minusculas(lista):\n",
    "    convertir = []\n",
    "    for i in range(len(lista)):\n",
    "        convertir.append(lista[i].lower())\n",
    "    return convertir\n",
    "\n",
    "#Genera un diccionario PD entrenado hacia adelante (-no se usa, solo para pruebas-)\n",
    "def entrenar_PD_adelante(df, N):           \n",
    "    PD={}\n",
    "    \n",
    "    for lista in df:\n",
    "        for i in range(len(lista)):\n",
    "            for n in range(1,N+1):\n",
    "                if (i+n<len(lista)):\n",
    "                    agregar_palabra(PD,lista[i],lista[i+n])\n",
    "            sumar_aparicion(PD, lista[i])    \n",
    "    return PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generación de diccionarios\n",
    "N=3\n",
    "P = entrenar_P(df_data['palabras'])\n",
    "PD = entrenar_PD(df_data['palabras'], N)\n",
    "P_nada = 0.001\n",
    "\n",
    "entrenar_online = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrHEaPPcj30i",
    "outputId": "33cfb55d-d899-4720-c22b-71dfe9f51303"
   },
   "outputs": [],
   "source": [
    "def recomendacion_bayesiana(frase):\n",
    "    \n",
    "    D=minusculas(frase)    \n",
    "    \n",
    "    Horizonte = N\n",
    "    h_MAP = \"\"\n",
    "    p_MAP = 0\n",
    "    \n",
    "    for h in P:\n",
    "        \n",
    "        if h != '_total':\n",
    "            prob = P[h]/P['_total']\n",
    "            for d in D[-Horizonte:]:\n",
    "                prob_dada = PD[h].get(d, P_nada)\n",
    "                if prob_dada == P_nada:\n",
    "                    prob = prob * prob_dada\n",
    "                else:                    \n",
    "                    prob = prob * prob_dada/PD[h]['_apariciones']\n",
    "                \n",
    "            if prob > p_MAP:\n",
    "                h_MAP , p_MAP = h , prob\n",
    "    #print(h_MAP)\n",
    "\n",
    "    return h_MAP\n",
    "\n",
    "##### LOOP PRINCIPAL #####\n",
    "\n",
    "print(\"Ingrese la frase dando ENTER luego de \\x1b[3mcada palabra\\x1b[0m.\")\n",
    "print(\"Ingrese sólo ENTER para aceptar la recomendación sugerida, o escriba la siguiente palabra y de ENTER\")\n",
    "print(\"Ingrese '.' para comenzar con una frase nueva.\")\n",
    "print(\"Ingrese '..' para terminar el proceso.\")\n",
    "\n",
    "frase = []\n",
    "palabra_sugerida = \"\"\n",
    "while 1:\n",
    "    palabra = input(\">> \")\n",
    "\n",
    "    if palabra == \"..\":\n",
    "        break\n",
    "\n",
    "    elif palabra == \".\":\n",
    "        if entrenar_online:\n",
    "            frase = minusculas(frase)\n",
    "            agregar_palabras_P(P, frase)\n",
    "            agregar_palabras_PD(PD, frase, N)\n",
    "            \n",
    "        print(\"----- Comenzando frase nueva -----\")\n",
    "        frase = []\n",
    "\n",
    "    elif palabra == \"\": # acepta última palabra sugerida\n",
    "        frase.append(palabra_sugerida)\n",
    "\n",
    "    else: # escribió una palabra\n",
    "        frase.append(palabra)\n",
    "\n",
    "    if frase:\n",
    "        palabra_sugerida = recomendacion_bayesiana(frase)\n",
    "    \n",
    "        frase_propuesta = frase.copy()\n",
    "        frase_propuesta.append(\"\\x1b[3m\"+ palabra_sugerida +\"\\x1b[0m\")\n",
    "    \n",
    "        print(\" \".join(frase_propuesta))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
